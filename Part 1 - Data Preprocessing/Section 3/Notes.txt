
=**=**= THE MACHINE LEARNING PROCESS =**=**=

‚óâ DATA PRE-PROCESSING
    - Import the data
    - Clean the data
    - Encode categorical variables
    - Split into training & test sets
    - Apply feature scaling (Normalization or Standardization)
‚óâ MODELLING
    - Build the model
    - Train the model
    - Tune hyperparameters (if needed)
    - Make predictions
‚óâ EVALUATION
    - Calculate performance metrics
    - Compare with baseline models
    - Interpret results & make improvements
-----------------------------------------

üî∂ INDEPENDENT VARIABLES VECTOR (FEATURES): X
Definition: Features are the input variables used to predict the outcome Y.

üî∂ DEPENDENT VARIABLE VECTOR (TARGET): Y
Definition: The dependent variable is the output or the value we are trying to predict.

‚óà Example: 
≈∑ = b0 + b1X1 + b2X2
Dataset = Train set (80%) + Test set (20%)
Output: Predicted values(≈∑) VS Actual value(y)

üî∂ FEATURE SCALING:
* Always applied to columns
* Out of multiple techniques of FS will focus on:
    
    -‚óà NORMALIZATION: recommended for some specific scenarios
        X' = (X - Xmin) / (Xmax - Xmin)
        [0 ; 1]
        
    -‚óà STANDARDIZATION: works all the time
        X' = (X - Avg) / Standard Deviation
        [-3 ; +3]
------------------------------------------
‚ùì Q: Feature Scaling: Before or After Splitting?
‚úÖ A: Feature Scaling should be applied AFTER splitting the dataset.

Key Reasons:
1Ô∏è‚É£ Prevent Data Leakage ‚Üí If you scale before splitting, the test set gets influenced by the entire dataset‚Äôs statistics (mean, std), which makes the model indirectly learn from it.
2Ô∏è‚É£ Real-World Simulation ‚Üí In production, models encounter new, unseen data. The test set should only be scaled using parameters learned from the training set to mimic real-world scenarios.
